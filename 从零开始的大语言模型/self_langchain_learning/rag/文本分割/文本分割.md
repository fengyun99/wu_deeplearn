# 文本分割

一旦加载了文档，您通常会想要转换它们以更好地适应您的应用程序。最简单的例子是，您可能希望将长文档分成更小的块，以便适合模型的上下文窗口。LangChain有许多内置的文档转换器，可以方便地拆分、组合、过滤和操作文档。

当您想要处理长文本时，有必要将该文本分割成块。虽然这听起来很简单，但这里有很多潜在的复杂性。理想情况下，您希望将语义相关的文本片段保持在一起。“语义相关”的含义可能取决于文本的类型。本笔记本展示了实现这一目标的几种方法。

在高层次上，文本分割器的工作方式如下:

- 将文本分成语义上有意义的小块(通常是句子)。

- 开始将这些小块组合成一个更大的块，直到达到一定的大小(由某个函数测量)。

- 一旦你达到这个大小，让这个块成为它自己的文本块，然后开始创建一个有一些重叠的新文本块(以保持块之间的上下文)。

这意味着有两个不同的轴，你可以自定义你的文本分割器:

- 文本是如何分割的

- 如何测量块大小

## 文本分割器的类型
LangChain提供了许多不同类型的文本分割器。下面的表格列出了所有这些，以及一些特征:

Name:文本分割器的名称

Splits On:这个文本分割器如何分割文本

Adds Metadata:该文本分割器是否添加关于每个块来自何处的元数据。

Description:对分配器的描述，包括何时使用的建议。

| Name | Splits On    | Adds Metadata | Description                                              |
|------|--------------|------------|----------------------------------------------------------|
| Recursive | 用户自定义字符的列表   |            | 递归分割文本。递归地分割文本的目的是试图保持相关的文本片段彼此相邻。这是开始分割文本的推荐方法。         |
| HTML | HTML特定字符     | YES        | 基于特定于html的字符拆分文本。值得注意的是，这增加了有关数据块来自何处的相关信息(基于HTML)。      |
| Markdown | Markdown特定字符 | YES        | 根据Markdown标记字符拆分文本。值得注意的是，这添加了关于该块来自何处的相关信息(基于Markdown)。 |
| Code | 代码(Python, JS)特定字符 |            | 基于特定于编码语言的字符拆分文本。有15种不同的语言可供选择。                          |
| Token | Tokens     |            | 分割TOKENS上的文本。有几种不同的方法来衡量TOKEN。                           |
|Character|用户定义的字符|| 根据用户定义的字符拆分文本。一个更简单的方法。                                  |
|[Experimental] Semantic Chunker|句子|| 首先拆分句子。然后，如果它们在语义上足够相似，就将它们相邻地组合在一起。取自[Greg Kamradt](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/5_Levels_Of_Text_Splitting.ipynb)               |

## 评估文本分割器
您可以使用[Greg Kamradt](https://chunkviz.up.railway.app/)创建的Chunkviz实用程序来评估文本分割器。Chunkviz是一个很好的工具，可以可视化你的文本分配器是如何工作的。它将向您展示文本是如何分割的，并帮助您调整分割参数。

## 其他文档转换
文本分割只是您可能希望在将文档传递给LLM之前对其进行转换的一个示例。转到集成，获取关于与第三方工具集成的内置文档转换器的文档。

https://python.langchain.com/docs/integrations/document_transformers/